# a re-implementation of the quantseqPool analysis.sh 
configfile: "config.yaml"
working_dir = config['working_dir']
star_genome_dir = config['star_genome']
sample_sheet = config['sample_sheet']
gtf = config['gtf']
tx_fa = config['tx_fa']
import pandas as pd
SAMPLES = pd.read_csv(sample_sheet).iloc[:,0]

shell("conda config --add envs_dirs /home/cachris/.conda/envs/")

rule all:
    input:
        expand(working_dir +   "salmon/{sample}/quant.sf" ,sample = SAMPLES)


rule demux:
    input:
        r1 = config['bulk_rna_r1'],
        r2 = config['bulk_rna_r2'],
        samples = sample_sheet,
    output:
        stats = working_dir + "demux_fastqs/demultipexing_stats.tsv",
        for_all = expand(working_dir + "demux_fastqs/{sample}_R1.fastq.gz", sample= SAMPLES),
        for_all2 = expand(working_dir + "demux_fastqs/{sample}_R2.fastq.gz", sample= SAMPLES)
    conda:
        "chris-base"
    log: 
        working_dir + "logs/idemux.log",
    params:
        dirr = working_dir + "demux_fastqs",
    threads:
        20
    shell:
        "idemuxCPP -m /home/cachris/.conda/envs/chris-base/share/idemuxcpp/barcodes/ --r1 {input.r1} --r2 {input.r2}  --sample-sheet {input.samples}  --out {params.dirr}  > {log} 2>&1"



rule UMI_extract:
    input:
        r1 = working_dir + "demux_fastqs/{sample}_R1.fastq.gz",
        r2 = working_dir + "demux_fastqs/{sample}_R2.fastq.gz",
    output:
        r1 = working_dir + "extracted_fastqs/{sample}.R1.fastq.gz",
        r2 = working_dir + "extracted_fastqs/{sample}.R2.fastq.gz",
    log:
        working_dir + "logsUMI_extract/{sample}.log",
    conda:
        "quantseq"
    shell:
        """
        umi_tools extract \
        --extract-method=string --bc-pattern X  \
        --bc-pattern2 NNNNNNNNNN \
        -L {log} \
        -S {output.r1} \
        -I {input.r1} \
        --read2-in={input.r2} \
        --read2-out={output.r2}  
        """



rule cutadapt:
    input:
        r1 = working_dir + "extracted_fastqs/{sample}.R1.fastq.gz",
    output:
        r1 = working_dir + "trimmed_fastqs/{sample}.R1.fastq.gz",
    log: 
        out = "{sample}_stdout.log",
        err = "{sample}_stderr.err"
    conda:
        "quantseq"
    shell:
        """
        cutadapt -m 20 -O 20 -a "polyA=A{{20}}" \
        -a "QUALITY=G{{20}}" -n 2 {input.r1} 2>>{log.err} | \
        cutadapt  -m 20 -O 3 \
        --nextseq-trim=10  \
        -a "r1adapter=A{{18}}AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC;min_overlap=3;max_error_rate=0.100000" - \
        | cutadapt -m 20 -O 3 \
        -a "r1polyA=A{{18}}" - | \
        cutadapt -m 20 -O 20 \
        -g "r1adapter=AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC;min_overlap=20" \
        --discard-trimmed -o {output.r1} - 2> {log.err} 1> {log.out}
        """


rule star_pe:
    input:
        fq1 = working_dir + "trimmed_fastqs/{sample}.R1.fastq.gz", 
        #fq2 = working_dir + "trimmed_fastqs/{sample}.R2.fastq.gz",
        # path to STAR reference genome index
        idx=star_genome_dir,
    output:
        # see STAR manual for additional output files
        aln = working_dir + "star/{sample}/Aligned.toTranscriptome.out.bam",
        log = working_dir + "star/{sample}/Log.out",
        log_final = working_dir + "star/{sample}/Log.final.out", 
    params:
        out_prefix = working_dir + "star/{sample}/",
    log:
        working_dir + "logs/star/{sample}.log",
    threads: 15
    conda:
        "chris-base"
    shell:
        """
        STAR \
        --runThreadN 15 \
        --genomeDir {input.idx} \
        --readFilesIn {input.fq1} \
        --readFilesCommand zcat \
        --quantMode TranscriptomeSAM \
        --outSAMtype BAM SortedByCoordinate \
        --outFilterType BySJout \
        --outFilterMultimapNmax 200 \
        --alignSJoverhangMin 8 \
        --alignSJDBoverhangMin 1 \
        --outFilterMismatchNmax 999 \
        --outFilterMismatchNoverLmax 0.6 \
        --alignIntronMin 20 \
        --alignIntronMax 1000000 \
        --alignMatesGapMax 1000000 \
        --limitOutSJcollapsed 5000000 \
        --outSAMattributes NH HI NM MD \
        --outFileNamePrefix {params.out_prefix} > {log}       
        """


rule sort:
    input:
	    bam = working_dir + "star/{sample}/Aligned.toTranscriptome.out.bam",
    output:
	    bams = working_dir + "star/{sample}/Aligned.toTranscriptome.sort.out.bam",
    shell:
        """
        samtools sort {input.bam} -o {output.bams}
        """


rule index:
    input:
        bam = working_dir + "star/{sample}/Aligned.toTranscriptome.sort.out.bam",
    output:
        bai = working_dir + "star/{sample}/Aligned.toTranscriptome.sort.out.bam.bai",
    params:
        new_dir = working_dir + "dedup_bams/{sample}/"
    threads:
	    1
    conda:
        "chris-base"
    shell:
        """
        samtools index -@ {threads} {input.bam} 
       
        """




rule dedup:
    input:
        bam = working_dir + "star/{sample}/Aligned.toTranscriptome.sort.out.bam",
        bai = working_dir + "star/{sample}/Aligned.toTranscriptome.sort.out.bam.bai",
    output:
        bam = working_dir + "dedup_bams/{sample}/Aligned.toTranscriptome.out.bam",
       # stats = working_dir + "dedup_bams/{sample}/deduplicated.txt",
    params:
        stats = working_dir + "dedup_bams/{sample}/deduplicated.txt",
    log:
        working_dir + "logs/dedup/{sample}.log",
    conda:
        "quantseq"
    shell:
        """
        umi_tools dedup \
        -I {input.bam} \
        -S {output.bam} \
        --multimapping-detection-method=NH \
        --output-stats={params.stats} \
        > {log} 2>&1 
        """


rule salmon:
    input:
	    bam = working_dir + "dedup_bams/{sample}/Aligned.toTranscriptome.out.bam"
    output:
	    quant = working_dir + "salmon/{sample}/quant.sf",
    params:
	    tx_fa = tx_fa,
	    out = working_dir + "salmon/{sample}",
    conda:
        "salmon"
    shell:
        """
        salmon quant -a {input.bam} -t {params.tx_fa} -o {params.out} -l a
        """

        
